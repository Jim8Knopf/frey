# ==================================================================================
# FREY VOICE ASSISTANT CONFIGURATION FOR HOME ASSISTANT
# ==================================================================================
# This file provides shell commands for Home Assistant voice control via Ollama LLM
#
# Include this in your configuration.yaml:
#   shell_command: !include voice_assistant_config.yaml
#
# The LLM (Ollama with {{ voice_assistant.ollama_model }}) understands natural language
# and calls these commands dynamically based on user intent.
# ==================================================================================

# Smart Docker control commands
# The LLM calls these with parameters based on what you say
shell_command:
  # Docker container management (calls frey-docker-control.sh)
  frey_docker: "/usr/local/bin/frey-docker-control {{ action }} {{ service }}"

  # System information
  frey_system_info: "echo 'System Status:' && uptime && echo '' && free -h && echo '' && df -h /opt/frey"
  frey_list_services: "/usr/local/bin/frey-docker-control list"

# ==================================================================================
# OLLAMA CONVERSATION AGENT CONFIGURATION
# ==================================================================================
# Configure this in Home Assistant: Settings → Devices & Services → Extended OpenAI
#
# System Prompt (tell Ollama how to use these commands):
#
# You are Frey, a helpful voice assistant for managing a home server.
#
# You can control Docker services using the frey_docker command with two parameters:
# - action: start, stop, restart, or status
# - service: jellyfin, sonarr, radarr, bazarr, lidarr, prowlarr, qbittorrent,
#            audiobookshelf, jellyseerr, homeassistant, n8n, portainer, grafana,
#            prometheus, traefik, adguard, or any container name
#
# You can also:
# - Get system info: frey_system_info (no parameters)
# - List all services: frey_list_services (no parameters)
#
# Examples:
# User: "Start Jellyfin" → Call: frey_docker(action="start", service="jellyfin")
# User: "Is Sonarr running?" → Call: frey_docker(action="status", service="sonarr")
# User: "What services are running?" → Call: frey_list_services()
# User: "What's the system status?" → Call: frey_system_info()
#
# Always respond conversationally and confirm actions taken.
# Keep responses concise since they will be spoken aloud.
#
# Service name variations (all these work):
# - "Jellyfin" or "Jelly"
# - "Sonarr" or "Sonar"
# - "Radarr" or "Radar"
# - "qBittorrent" or "torrent"
# - "Audiobookshelf" or "audiobook"
# - "Home Assistant" or "home"
#
# Protected services (cannot be stopped):
# - homeassistant, ollama, piper, wyoming-whisper, openwakeword, traefik
# ==================================================================================

# ==================================================================================
# FUNCTION CALLING SETUP (Extended OpenAI / Ollama)
# ==================================================================================
# When configuring Extended OpenAI integration with Ollama, enable function calling
# and define these functions:
#
# Function 1: frey_docker
# Description: Control Docker containers (start, stop, restart, check status)
# Parameters:
#   - action (required, enum): start, stop, restart, status
#   - service (required, string): Service name (jellyfin, sonarr, radarr, etc.)
#
# Function 2: frey_list_services
# Description: List all running Docker containers
# Parameters: None
#
# Function 3: frey_system_info
# Description: Get system information (uptime, memory, disk usage)
# Parameters: None
#
# With function calling enabled, the LLM will automatically:
# 1. Understand your voice command
# 2. Choose the right function to call
# 3. Extract parameters from your natural language
# 4. Execute the command
# 5. Respond naturally with the result
# ==================================================================================

# ==================================================================================
# AVAILABLE SERVICES
# ==================================================================================
# These services are available for voice control:
#
# Media Services:
{% for service in ['jellyfin', 'sonarr', 'radarr', 'bazarr', 'lidarr', 'prowlarr', 'qbittorrent', 'audiobookshelf', 'jellyseerr'] %}
#   - {{ service }}
{% endfor %}
#
# Infrastructure:
{% for service in ['portainer', 'traefik', 'dockge', 'authentik', 'adguardhome'] %}
#   - {{ service }}
{% endfor %}
#
# Automation:
{% for service in ['homeassistant', 'n8n', 'ollama'] %}
#   - {{ service }}
{% endfor %}
#
# Monitoring:
{% for service in ['grafana', 'prometheus', 'uptime-kuma'] %}
#   - {{ service }}
{% endfor %}
#
# The LLM understands all of these and their common variations.
# ==================================================================================

# ==================================================================================
# VOICE COMMAND EXAMPLES
# ==================================================================================
# Natural language commands that work out of the box:
#
# Service Control:
#   "Start Jellyfin"
#   "Stop Sonarr"
#   "Restart Radarr"
#   "Turn on the torrent client"
#
# Service Status:
#   "Is Jellyfin running?"
#   "Check the status of Sonarr"
#   "What's the status of the media services?"
#
# System Information:
#   "What services are running?"
#   "List all containers"
#   "Show me the system status"
#   "How much disk space is left?"
#   "What's the memory usage?"
#
# The LLM handles variations, synonyms, and natural phrasing automatically.
# ==================================================================================
